import csv
import os
import re
import time
from urllib.parse import urljoin

from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC


# ---------------- –ü—ä—Ç–∏—â–∞ ----------------
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
SKU_CSV = os.path.join(BASE_DIR, "sku_list_filstar.csv")
RES_CSV = os.path.join(BASE_DIR, "results_filstar.csv")
NF_CSV  = os.path.join(BASE_DIR, "not_found_filstar.csv")


# ---------------- WebDriver ----------------
def create_driver():
    opts = Options()
    opts.add_argument("--headless=new")
    opts.add_argument("--no-sandbox")
    opts.add_argument("--disable-dev-shm-usage")
    opts.add_argument("--window-size=1440,1000")
    opts.add_argument("--lang=bg-BG,bg,en-US,en")
    opts.add_argument(
        "--user-agent=Mozilla/5.0 (X11; Linux x86_64) "
        "AppleWebKit/537.36 (KHTML, like Gecko) Chrome/127 Safari/537.36"
    )
    opts.add_experimental_option("excludeSwitches", ["enable-automation"])
    opts.add_experimental_option("useAutomationExtension", False)

    driver = webdriver.Chrome(options=opts)
    driver.set_page_load_timeout(30)
    return driver


def click_cookies_if_any(driver):
    candidates = [
        (By.CSS_SELECTOR, "#onetrust-accept-btn-handler"),
        (By.XPATH, "//button[contains(.,'–ü—Ä–∏–µ–º–∞–º')]"),
        (By.XPATH, "//*[contains(.,'–ü—Ä–∏–µ–º–∞–º –±–∏—Å–∫–≤–∏—Ç–∫–∏—Ç–µ')]"),
        (By.XPATH, "//button[contains(.,'Accept')]"),
    ]
    for how, sel in candidates:
        try:
            WebDriverWait(driver, 3).until(EC.element_to_be_clickable((how, sel))).click()
            break
        except Exception:
            pass


def norm(s):
    return str(s).strip()


# ---------------- –¢—ä—Ä—Å–µ–Ω–µ –Ω–∞ –ø—Ä–æ–¥—É–∫—Ç ----------------
def find_product_link_via_search(driver, sku) -> str | None:
    """–û—Ç–≤–∞—Ä—è /search?term=<SKU> –∏ –≤–∑–∏–º–∞ –ø—ä—Ä–≤–∏—è —Ä–µ–∞–ª–µ–Ω –ø—Ä–æ–¥—É–∫—Ç –æ—Ç .product-item-wapper a.product-name"""
    q = norm(sku)
    search_urls = [
        f"https://filstar.com/search?term={q}",
        f"https://filstar.com/bg/search?term={q}",
        f"https://filstar.com/en/search?term={q}",
    ]
    for surl in search_urls:
        try:
            driver.get(surl)
            click_cookies_if_any(driver)
            WebDriverWait(driver, 12).until(
                EC.presence_of_all_elements_located((By.CSS_SELECTOR, ".product-item-wapper a.product-name"))
            )
            anchors = driver.find_elements(By.CSS_SELECTOR, ".product-item-wapper a.product-name")
            for a in anchors:
                href = (a.get_attribute("href") or "").strip()
                if not href:
                    continue
                if href.startswith("/"):
                    href = urljoin("https://filstar.com", href)
                return href
        except Exception:
            continue
    return None


# ---------------- –ü–æ–º–æ—â–Ω–∏: –Ω–∞–º–∏—Ä–∞–Ω–µ –Ω–∞ —Ä–µ–¥ –∏ —Ü–µ–Ω–∞ ----------------
def find_variant_row_by_sku(driver, sku):
    """
    –ù–∞–º–∏—Ä–∞ <tr>, –∫—ä–¥–µ—Ç–æ –∫–æ–ª–æ–Ω–∞—Ç–∞ –ö–û–î (td.scrollable-td.td-sky) —Å—ä–¥—ä—Ä–∂–∞ —Ç–æ—á–Ω–æ SKU.
    –¢–æ–≤–∞ —Å—ä–≤–ø–∞–¥–∞ —Å —Ç–≤–æ—è HTML.
    """
    q = norm(sku)
    xps = [
        f"//table[@id='fast-order-table']//tr[td[contains(@class,'td-sky')][contains(normalize-space(),'{q}')]]",
        f"//tr[td[contains(@class,'td-sky')][contains(normalize-space(),'{q}')]]",
    ]
    for xp in xps:
        try:
            return driver.find_element(By.XPATH, xp)
        except Exception:
            continue
    # –ø–æ—Å–ª–µ–¥–µ–Ω fallback ‚Äì —Ç—ä—Ä—Å–∏ –∫–ª–µ—Ç–∫–∞ —Å –ö–û–î –∏ —Å–µ –≤—ä—Ä–Ω–∏ –∫—ä–º —Ä–µ–¥–∞
    try:
        cell = driver.find_element(By.XPATH, f"//td[contains(@class,'td-sky')][contains(normalize-space(),'{q}')]")
        return cell.find_element(By.XPATH, "./ancestor::tr")
    except Exception:
        return None


def extract_normal_price_from_row(row_el):
    """
    –í–∑–∏–º–∞ –ù–û–†–ú–ê–õ–ù–ê–¢–ê —Ü–µ–Ω–∞ –≤ –ª–µ–≤–∞ –æ—Ç —Ä–µ–¥–∞:
      - –∞–∫–æ –∏–º–∞ <strike>‚Ä¶ –ª–≤. ‚Üí —Ç–æ–≤–∞ –µ –Ω–æ—Ä–º–∞–ª–Ω–∞—Ç–∞ (—Å—Ç–∞—Ä–∞) —Ü–µ–Ω–∞
      - –∏–Ω–∞—á–µ –≤–∑–µ–º–∏ –≤–∏–¥–∏–º–∞—Ç–∞ –ª–≤. —Ü–µ–Ω–∞ –≤ —Ä–µ–¥–∞ (–∫–∞–∫—Ç–æ –µ –≤ –¥–∞–¥–µ–Ω–∏—è HTML ‚Äì –±–µ–∑ –Ω–∞–º–∞–ª–µ–Ω–∏–µ)
    """
    # 1) <strike>‚Ä¶ –ª–≤.
    try:
        strikes = row_el.find_elements(By.TAG_NAME, "strike")
        for st in strikes:
            raw = st.text.replace("\xa0", " ")
            m = re.search(r"(\d+[.,]?\d*)\s*–ª–≤", raw, flags=re.IGNORECASE)
            if m:
                return m.group(1).replace(",", ".")
    except Exception:
        pass

    # 2) —Ü–µ–ª–µ–≤–∞—Ç–∞ –∫–ª–µ—Ç–∫–∞ "–¶–ï–ù–ê –ù–ê –î–†–ï–ë–ù–û" ‚Üí –≤–∑–µ–º–∏ –ª–≤. –æ—Ç –≤—ä—Ç—Ä–µ—à–Ω–∏—è div
    try:
        price_td = row_el.find_element(By.XPATH, ".//td[.//span[contains(.,'–¶–ï–ù–ê –ù–ê –î–†–ï–ë–ù–û')]]")
        txt = price_td.text.replace("\xa0", " ")
        m = re.search(r"(\d+[.,]?\d*)\s*–ª–≤", txt, flags=re.IGNORECASE)
        if m:
            return m.group(1).replace(",", ".")
    except Exception:
        pass

    # 3) fallback: –≤—Å—è–∫–∞ –ª–≤. —Ü–µ–Ω–∞ –≤ —Ä–µ–¥–∞
    try:
        txt = row_el.text.replace("\xa0", " ")
        m = re.search(r"(\d+[.,]?\d*)\s*–ª–≤", txt, flags=re.IGNORECASE)
        if m:
            return m.group(1).replace(",", ".")
    except Exception:
        pass

    return None


def extract_qty_status_from_row(row_el):
    """
    –ö–æ–ª–∏—á–µ—Å—Ç–≤–∞—Ç–∞/—Å—Ç–∞—Ç—É—Å—ä—Ç –Ω–µ —Å–∞ –≤–∏–¥–∏–º–∏ –∑–∞ –∞–Ω–æ–Ω–∏–º–Ω–∏ –ø–æ—Ç—Ä–µ–±–∏—Ç–µ–ª–∏ –≤ —Ç–æ–∑–∏ —à–∞–±–ª–æ–Ω.
    –í—Å–µ –ø–∞–∫ —Ç—ä—Ä—Å–∏–º —Ç–µ–∫—Å—Ç–æ–≤–∏ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–∏; –∏–Ω–∞—á–µ –≤—Ä—ä—â–∞–º–µ Unknown/0.
    """
    status = "Unknown"
    qty = 0

    try:
        t = row_el.text.lower()
        if any(x in t for x in ["–∏–∑—á–µ—Ä–ø–∞–Ω", "–Ω—è–º–∞", "out of stock"]):
            status = "–ò–∑—á–µ—Ä–ø–∞–Ω"
        if any(x in t for x in ["–≤ –Ω–∞–ª–∏—á–Ω–æ—Å—Ç", "–Ω–∞–ª–∏—á–µ–Ω", "in stock"]):
            status = "–ù–∞–ª–∏—á–µ–Ω"
    except Exception:
        pass

    return status, qty


def save_debug_html(driver, sku):
    try:
        path = os.path.join(BASE_DIR, f"debug_{sku}.html")
        with open(path, "w", encoding="utf-8") as f:
            f.write(driver.page_source)
        print(f"   üêû –ó–∞–ø–∏—Å–∞—Ö HTML –∑–∞ {sku}: {path}")
    except Exception:
        pass


def scrape_product_page(driver, product_url, sku):
    """–ó–∞—Ä–µ–∂–¥–∞ –ø—Ä–æ–¥—É–∫—Ç–∞, –Ω–∞–º–∏—Ä–∞ —Ä–µ–¥–∞ –ø–æ SKU –∏ –≤–∞–¥–∏ —Ü–µ–Ω–∞/—Å—Ç–∞—Ç—É—Å."""
    driver.get(product_url)
    click_cookies_if_any(driver)
    time.sleep(1.0)
    try:
        driver.execute_script("window.scrollBy(0, 400);")
    except Exception:
        pass
    time.sleep(0.3)

    print(f"   üîé TITLE: {driver.title.strip()[:120]}")
    print(f"   üîé URL:   {driver.current_url}")

    row = find_variant_row_by_sku(driver, sku)
    if not row:
        save_debug_html(driver, sku)
        return "Unknown", 0, None

    price = extract_normal_price_from_row(row)
    status, qty = extract_qty_status_from_row(row)
    return status, qty, price


# ---------------- CSV I/O ----------------
def read_sku_codes(path):
    skus = []
    with open(path, newline="", encoding="utf-8") as f:
        r = csv.reader(f)
        header = next(r, None)  # –ø—Ä–æ–ø—É—Å–∫–∞–º–µ —Ö–µ–¥—ä—Ä–∞
        for row in r:
            if not row:
                continue
            val = (row[0] or "").strip()
            if not val or val.lower() == "sku":
                continue
            skus.append(val)
    if skus:
        print(f"   üßæ SKUs loaded ({len(skus)}): {', '.join(skus[:5])}{' ...' if len(skus)>5 else ''}")
    else:
        print("   üßæ No SKUs loaded from CSV.")
    return skus


def save_results(rows, path):
    os.makedirs(os.path.dirname(path), exist_ok=True)
    with open(path, "w", newline="", encoding="utf-8") as f:
        w = csv.writer(f)
        w.writerow(["SKU", "–ù–∞–ª–∏—á–Ω–æ—Å—Ç", "–ë—Ä–æ–π–∫–∏", "–¶–µ–Ω–∞ (–Ω–æ—Ä–º–∞–ª–Ω–∞ –ª–≤.)"])
        w.writerows(rows)


def save_not_found(skus, path):
    os.makedirs(os.path.dirname(path), exist_ok=True)
    with open(path, "w", newline="", encoding="utf-8") as f:
        w = csv.writer(f)
        w.writerow(["SKU"])
        for s in skus:
            w.writerow([s])


# ---------------- main ----------------
def main():
    skus = read_sku_codes(SKU_CSV)
    driver = create_driver()
    results, not_found = [], []

    try:
        for sku in skus:
            print(f"\n‚û°Ô∏è –û–±—Ä–∞–±–æ—Ç–≤–∞–º SKU: {sku}")

            product_url = find_product_link_via_search(driver, sku)
            if not product_url:
                print(f"‚ùå –ù–µ –Ω–∞–º–µ—Ä–∏—Ö –ø—Ä–æ–¥—É–∫—Ç –∑–∞ {sku} –≤ —Ç—ä—Ä—Å–∞—á–∫–∞—Ç–∞.")
                not_found.append(sku)
                continue

            print(f"  ‚úÖ –ü—Ä–æ–¥—É–∫—Ç –ª–∏–Ω–∫: {product_url}")
            status, qty, price = scrape_product_page(driver, product_url, sku)
            print(f"     ‚Üí –°—Ç–∞—Ç—É—Å: {status} | –ë—Ä–æ–π–∫–∏: {qty} | –¶–µ–Ω–∞: {price if price else '‚Äî'}")

            results.append([sku, status, qty, price or ""])
            time.sleep(0.3)

    finally:
        driver.quit()

    save_results(results, RES_CSV)
    save_not_found(not_found, NF_CSV)
    print(f"\n‚úÖ –ó–∞–ø–∞–∑–µ–Ω–∏ —Ä–µ–∑—É–ª—Ç–∞—Ç–∏: {RES_CSV}")
    print(f"‚ùå –ù–µ–Ω–∞–º–µ—Ä–µ–Ω–∏ SKU –∫–æ–¥–æ–≤–µ: {NF_CSV}")


if __name__ == "__main__":
    main()
