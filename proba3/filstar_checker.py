import csv
import os
import re
import time
from urllib.parse import urljoin

from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC


# ---------------- –ü—ä—Ç–∏—â–∞ ----------------
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
SKU_CSV = os.path.join(BASE_DIR, "sku_list_filstar.csv")
RES_CSV = os.path.join(BASE_DIR, "results_filstar.csv")
NF_CSV  = os.path.join(BASE_DIR, "not_found_filstar.csv")


# ---------------- WebDriver ----------------
def create_driver():
    opts = Options()
    opts.add_argument("--headless=new")
    opts.add_argument("--no-sandbox")
    opts.add_argument("--disable-dev-shm-usage")
    opts.add_argument("--window-size=1440,1000")
    opts.add_argument("--lang=bg-BG,bg,en-US,en")
    opts.add_argument(
        "--user-agent=Mozilla/5.0 (X11; Linux x86_64) "
        "AppleWebKit/537.36 (KHTML, like Gecko) Chrome/127 Safari/537.36"
    )
    opts.add_experimental_option("excludeSwitches", ["enable-automation"])
    opts.add_experimental_option("useAutomationExtension", False)

    driver = webdriver.Chrome(options=opts)
    driver.set_page_load_timeout(30)
    return driver


def click_cookies_if_any(driver):
    candidates = [
        (By.CSS_SELECTOR, "#onetrust-accept-btn-handler"),
        (By.XPATH, "//button[contains(.,'–ü—Ä–∏–µ–º–∞–º')]"),
        (By.XPATH, "//*[contains(.,'–ü—Ä–∏–µ–º–∞–º –±–∏—Å–∫–≤–∏—Ç–∫–∏—Ç–µ')]"),
        (By.XPATH, "//button[contains(.,'Accept')]"),
    ]
    for how, sel in candidates:
        try:
            WebDriverWait(driver, 3).until(EC.element_to_be_clickable((how, sel))).click()
            break
        except Exception:
            pass


def norm(s):
    return str(s).strip()


# ---------------- –¢—ä—Ä—Å–µ–Ω–µ –Ω–∞ –ø—Ä–æ–¥—É–∫—Ç ----------------
def find_product_link_via_search(driver, sku) -> str | None:
    """–û—Ç–≤–∞—Ä—è /search?term=<SKU> –∏ –≤–∑–∏–º–∞ –ø—ä—Ä–≤–∏—è —Ä–µ–∞–ª–µ–Ω –ø—Ä–æ–¥—É–∫—Ç –æ—Ç .product-item-wapper a.product-name"""
    q = norm(sku)
    search_urls = [
        f"https://filstar.com/search?term={q}",
        f"https://filstar.com/bg/search?term={q}",
        f"https://filstar.com/en/search?term={q}",
    ]
    for surl in search_urls:
        try:
            driver.get(surl)
            click_cookies_if_any(driver)
            WebDriverWait(driver, 12).until(
                EC.presence_of_all_elements_located((By.CSS_SELECTOR, ".product-item-wapper a.product-name"))
            )
            anchors = driver.find_elements(By.CSS_SELECTOR, ".product-item-wapper a.product-name")
            for a in anchors:
                href = (a.get_attribute("href") or "").strip()
                if not href:
                    continue
                if href.startswith("/"):
                    href = urljoin("https://filstar.com", href)
                return href
        except Exception:
            continue
    return None


# ---------------- –ü–æ–º–æ—â–Ω–∏: –Ω–∞–º–∏—Ä–∞–Ω–µ –Ω–∞ —Ä–µ–¥ –∏ —Ü–µ–Ω–∞ ----------------
def wait_variant_row_by_sku(driver, sku, timeout=12):
    """
    –ò–∑—á–∞–∫–≤–∞ —Ä–µ–¥–∞ (tr) –∑–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ—Ç–æ SKU:
      –ö–û–î –µ –≤ <td class="scrollable-td td-sky"> <span>–ö–û–î</span> 360947 </td>
    """
    q = norm(sku)
    xps = [
        f"//table[@id='fast-order-table']//tr[td[contains(@class,'td-sky')][contains(normalize-space(),'{q}')]]",
        f"//tr[td[contains(@class,'td-sky')][contains(normalize-space(),'{q}')]]",
    ]
    end = time.time() + timeout
    last_err = None
    while time.time() < end:
        for xp in xps:
            try:
                return driver.find_element(By.XPATH, xp)
            except Exception as e:
                last_err = e
        time.sleep(0.2)
    if last_err:
        raise last_err
    return None


def extract_normal_price_from_row(row_el):
    """
    –í–∑–∏–º–∞ –ù–û–†–ú–ê–õ–ù–ê–¢–ê —Ü–µ–Ω–∞ –≤ –ª–µ–≤–∞ –æ—Ç —Ä–µ–¥–∞:
      1) –∞–∫–æ –∏–º–∞ <strike>‚Ä¶ –ª–≤. ‚Üí –≤—Ä—ä—â–∞ –Ω–µ–≥–æ (—Å—Ç–∞—Ä–∞ —Ü–µ–Ω–∞);
      2) –∏–Ω–∞—á–µ –æ–±—Ö–æ–∂–¥–∞ –≤—Å–∏—á–∫–∏ td.scrollable-td –≤ —Ä–µ–¥–∞ –∏ –≤–∑–∏–º–∞ –ü–û–°–õ–ï–î–ù–ê–¢–ê ‚Äû‚Ä¶ –ª–≤.‚Äú.
         (–∏–∑–±—è–≥–≤–∞ —á–∏—Å–ª–∞—Ç–∞ –æ—Ç –∫–æ–ª–æ–Ω–∏ ‚Äû–†–∞–∑–º–µ—Ä / –î—ä–ª–∂–∏–Ω–∞ / –¢–µ—Å—Ç‚Äú)
    """
    # 1) strike
    try:
        strikes = row_el.find_elements(By.TAG_NAME, "strike")
        for st in strikes:
            raw = st.text.replace("\xa0", " ")
            m = re.search(r"(\d+[.,]?\d*)\s*–ª–≤", raw, flags=re.IGNORECASE)
            if m:
                return m.group(1).replace(",", ".")
    except Exception:
        pass

    # 2) –ø–æ—Å–ª–µ–¥–Ω–∞—Ç–∞ –ª–≤. –≤ –Ω—è–∫–æ–π –æ—Ç 'td.scrollable-td'
    try:
        tds = row_el.find_elements(By.CSS_SELECTOR, "td.scrollable-td")
        last_bgn = None
        for td in tds:
            txt = (td.text or "").replace("\xa0", " ")
            m = re.search(r"(\d+[.,]?\d*)\s*–ª–≤", txt, flags=re.IGNORECASE)
            if m:
                last_bgn = m.group(1).replace(",", ".")
        if last_bgn:
            return last_bgn
    except Exception:
        pass

    # 3) fallback: –≤—Å—è–∫–∞ ‚Äû‚Ä¶ –ª–≤.‚Äú –≤ —Ü–µ–ª–∏—è —Ä–µ–¥
    try:
        txt = row_el.text.replace("\xa0", " ")
        m = re.search(r"(\d+[.,]?\d*)\s*–ª–≤", txt, flags=re.IGNORECASE)
        if m:
            return m.group(1).replace(",", ".")
    except Exception:
        pass

    return None


def extract_qty_status_from_row(row_el):
    """
    –ö–æ–ª–∏—á–µ—Å—Ç–≤–∞—Ç–∞/—Å—Ç–∞—Ç—É—Å—ä—Ç –Ω–µ —Å–∞ –≤–∏–¥–∏–º–∏ –∑–∞ –∞–Ω–æ–Ω–∏–º–Ω–∏ –ø–æ—Ç—Ä–µ–±–∏—Ç–µ–ª–∏ –≤ —Ç–æ–∑–∏ —à–∞–±–ª–æ–Ω.
    –í—Å–µ –ø–∞–∫ —Ç—ä—Ä—Å–∏–º —Ç–µ–∫—Å—Ç–æ–≤–∏ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–∏; –∏–Ω–∞—á–µ –≤—Ä—ä—â–∞–º–µ Unknown/0.
    """
    status = "Unknown"
    qty = 0

    try:
        t = row_el.text.lower()
        if any(x in t for x in ["–∏–∑—á–µ—Ä–ø–∞–Ω", "–Ω—è–º–∞", "out of stock"]):
            status = "–ò–∑—á–µ—Ä–ø–∞–Ω"
        if any(x in t for x in ["–≤ –Ω–∞–ª–∏—á–Ω–æ—Å—Ç", "–Ω–∞–ª–∏—á–µ–Ω", "in stock"]):
            status = "–ù–∞–ª–∏—á–µ–Ω"
    except Exception:
        pass

    return status, qty


def save_debug_html(driver, sku):
    try:
        path = os.path.join(BASE_DIR, f"debug_{sku}.html")
        with open(path, "w", encoding="utf-8") as f:
            f.write(driver.page_source)
        print(f"   üêû –ó–∞–ø–∏—Å–∞—Ö HTML –∑–∞ {sku}: {path}")
    except Exception:
        pass


def scrape_product_page(driver, product_url, sku):
    """–ó–∞—Ä–µ–∂–¥–∞ –ø—Ä–æ–¥—É–∫—Ç–∞, –∏–∑—á–∞–∫–≤–∞ —Ç–∞–±–ª–∏—Ü–∞—Ç–∞ –∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–∏—è —Ä–µ–¥ –∑–∞ SKU, –≤–∞–¥–∏ —Ü–µ–Ω–∞/—Å—Ç–∞—Ç—É—Å."""
    driver.get(product_url)
    click_cookies_if_any(driver)

    # 1) –∏–∑—á–∞–∫–∞–π —Ç–∞–±–ª–∏—Ü–∞—Ç–∞ –¥–∞ —Å–µ –ø–æ—è–≤–∏
    try:
        WebDriverWait(driver, 12).until(EC.presence_of_element_located((By.ID, "fast-order-table")))
    except Exception:
        # –Ω—è–∫–æ–∏ –ø—Ä–æ–¥—É–∫—Ç–∏ –Ω—è–º–∞—Ç —Ç–∞–±–ª–∏—Ü–∞ (–±–µ–∑ –≤–∞—Ä–∏–∞–Ω—Ç–∏) ‚Äî –ø—Ä–æ–¥—ä–ª–∂–∞–≤–∞–º–µ –¥–∞ —Ç—ä—Ä—Å–∏–º —Ä–µ–¥ –ø–æ SKU
        pass

    # 2) –∏–∑—á–∞–∫–∞–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω–∏—è —Ä–µ–¥ –∑–∞ SKU
    try:
        row = wait_variant_row_by_sku(driver, sku, timeout=12)
    except Exception:
        row = None

    print(f"   üîé TITLE: {driver.title.strip()[:120]}")
    print(f"   üîé URL:   {driver.current_url}")

    if not row:
        save_debug_html(driver, sku)
        return "Unknown", 0, None

    price = extract_normal_price_from_row(row)
    status, qty = extract_qty_status_from_row(row)
    return status, qty, price


# ---------------- CSV I/O ----------------
def read_sku_codes(path):
    skus = []
    with open(path, newline="", encoding="utf-8") as f:
        r = csv.reader(f)
        header = next(r, None)  # –ø—Ä–æ–ø—É—Å–∫–∞–º–µ —Ö–µ–¥—ä—Ä–∞
        for row in r:
            if not row:
                continue
            val = (row[0] or "").strip()
            if not val or val.lower() == "sku":
                continue
            skus.append(val)
    if skus:
        print(f"   üßæ SKUs loaded ({len(skus)}): {', '.join(skus[:5])}{' ...' if len(skus)>5 else ''}")
    else:
        print("   üßæ No SKUs loaded from CSV.")
    return skus


def save_results(rows, path):
    os.makedirs(os.path.dirname(path), exist_ok=True)
    with open(path, "w", newline="", encoding="utf-8") as f:
        w = csv.writer(f)
        w.writerow(["SKU", "–ù–∞–ª–∏—á–Ω–æ—Å—Ç", "–ë—Ä–æ–π–∫–∏", "–¶–µ–Ω–∞ (–Ω–æ—Ä–º–∞–ª–Ω–∞ –ª–≤.)"])
        w.writerows(rows)


def save_not_found(skus, path):
    os.makedirs(os.path.dirname(path), exist_ok=True)
    with open(path, "w", newline="", encoding="utf-8") as f:
        w = csv.writer(f)
        w.writerow(["SKU"])
        for s in skus:
            w.writerow([s])


# ---------------- main ----------------
def main():
    skus = read_sku_codes(SKU_CSV)
    driver = create_driver()
    results, not_found = [], []

    try:
        for sku in skus:
            print(f"\n‚û°Ô∏è –û–±—Ä–∞–±–æ—Ç–≤–∞–º SKU: {sku}")

            product_url = find_product_link_via_search(driver, sku)
            if not product_url:
                print(f"‚ùå –ù–µ –Ω–∞–º–µ—Ä–∏—Ö –ø—Ä–æ–¥—É–∫—Ç –∑–∞ {sku} –≤ —Ç—ä—Ä—Å–∞—á–∫–∞—Ç–∞.")
                not_found.append(sku)
                continue

            print(f"  ‚úÖ –ü—Ä–æ–¥—É–∫—Ç –ª–∏–Ω–∫: {product_url}")
            status, qty, price = scrape_product_page(driver, product_url, sku)
            print(f"     ‚Üí –°—Ç–∞—Ç—É—Å: {status} | –ë—Ä–æ–π–∫–∏: {qty} | –¶–µ–Ω–∞: {price if price else '‚Äî'}")

            results.append([sku, status, qty, price or ""])
            time.sleep(0.2)

    finally:
        driver.quit()

    save_results(results, RES_CSV)
    save_not_found(not_found, NF_CSV)
    print(f"\n‚úÖ –ó–∞–ø–∞–∑–µ–Ω–∏ —Ä–µ–∑—É–ª—Ç–∞—Ç–∏: {RES_CSV}")
    print(f"‚ùå –ù–µ–Ω–∞–º–µ—Ä–µ–Ω–∏ SKU –∫–æ–¥–æ–≤–µ: {NF_CSV}")


if __name__ == "__main__":
    main()
